{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ваше распоряжение предоставлена директория users ('./Root/users'). В данной директории содержатся csv-файлы, в каждом из которых хранится информация об идентификаторах пользователей (user_id) и ссылки на их фотографии (image_url). Файлов в директории может быть сколько угодно.\n",
    "\n",
    "Вам необходимо написать функцию concat_user_files(path), параметром которой является path — путь до директории. Функция должна объединить информацию из предоставленных вам файлов в один DataFrame и вернуть его."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список названий всех файлов, находящихся в директории, вы можете получить с помощью функции os.listdir(path) из модуля os. Отсортируйте полученный список, прежде чем производить объединение файлов.\n",
    "\n",
    "Обратите внимание, что метод os.listdir() возвращает только названия файлов в указанной директории, а при чтении файла необходимо указывать полный путь до него.\n",
    "\n",
    "Не забудьте обновить индексы результирующей таблицы после объединения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def concat_user_files(path):\n",
    "    # Получение списка файлов в директории и сортировка\n",
    "    files = sorted(os.listdir(path))\n",
    "    \n",
    "    # Инициализация пустого списка для хранения DataFrame\n",
    "    dataframes = []\n",
    "    \n",
    "    # Чтение каждого файла и добавление его в список\n",
    "    for file in files:\n",
    "        file_path = os.path.join(path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    # Объединение всех DataFrame в один\n",
    "    result_df = pd.concat(dataframes, ignore_index=True)\n",
    "    # Удаление дубликатов\n",
    "    result_df = result_df.drop_duplicates()\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Даны две таблицы: items_df, в которой содержится информация о наличии товаров на складе, и purchase_df с данными о покупках товаров.\n",
    "\n",
    "Первая:\n",
    "\n",
    "items_df = pd.DataFrame({\n",
    "    'item_id': [417283, 849734, 132223, 573943, 19475, 3294095, 382043, 302948, 100132, 312394],\n",
    "    'vendor': ['Samsung', 'LG', 'Apple', 'Apple', 'LG', 'Apple', 'Samsung', 'Samsung', 'LG', 'ZTE'],\n",
    "    'stock_count': [54, 33, 122, 18, 102, 43, 77, 143, 60, 19]\n",
    "})\n",
    "Вторая:\n",
    "\n",
    "purchase_df = pd.DataFrame({\n",
    "    'purchase_id': [101, 101, 101, 112, 121, 145, 145, 145, 145, 221],\n",
    "    'item_id': [417283, 849734, 132223, 573943, 19475, 3294095, 382043, 302948, 103845, 100132],\n",
    "    'price': [13900, 5330, 38200, 49990, 9890, 33000, 67500, 34500, 89900, 11400]\n",
    "})\n",
    "Информация в таблицах представлена в виде следующих столбцов:\n",
    "\n",
    "item_id — идентификатор модели;\n",
    "vendor — производитель модели;\n",
    "stock_count — имеющееся на складе количество данных моделей (в штуках);\n",
    "purchase_id — идентификатор покупки;\n",
    "price — стоимость модели в покупке.\n",
    "Вам необходимо сделать следующее:\n",
    "\n",
    "Сформируйте DataFrame merged, так чтобы после объединения purchase_df и items_df остались модели, которые учтены на складе и имели продажи.\n",
    "\n",
    "На основе таблицы merged найдите суммарную выручку, которую можно было бы получить от продажи всех товаров, имеющихся на складе. Результат занесите в переменную income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>vendor</th>\n",
       "      <th>stock_count</th>\n",
       "      <th>purchase_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>417283</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>54</td>\n",
       "      <td>101</td>\n",
       "      <td>13900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>849734</td>\n",
       "      <td>LG</td>\n",
       "      <td>33</td>\n",
       "      <td>101</td>\n",
       "      <td>5330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132223</td>\n",
       "      <td>Apple</td>\n",
       "      <td>122</td>\n",
       "      <td>101</td>\n",
       "      <td>38200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>573943</td>\n",
       "      <td>Apple</td>\n",
       "      <td>18</td>\n",
       "      <td>112</td>\n",
       "      <td>49990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19475</td>\n",
       "      <td>LG</td>\n",
       "      <td>102</td>\n",
       "      <td>121</td>\n",
       "      <td>9890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3294095</td>\n",
       "      <td>Apple</td>\n",
       "      <td>43</td>\n",
       "      <td>145</td>\n",
       "      <td>33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>382043</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>77</td>\n",
       "      <td>145</td>\n",
       "      <td>67500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>302948</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>143</td>\n",
       "      <td>145</td>\n",
       "      <td>34500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100132</td>\n",
       "      <td>LG</td>\n",
       "      <td>60</td>\n",
       "      <td>221</td>\n",
       "      <td>11400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id   vendor  stock_count  purchase_id  price\n",
       "0   417283  Samsung           54          101  13900\n",
       "1   849734       LG           33          101   5330\n",
       "2   132223    Apple          122          101  38200\n",
       "3   573943    Apple           18          112  49990\n",
       "4    19475       LG          102          121   9890\n",
       "5  3294095    Apple           43          145  33000\n",
       "6   382043  Samsung           77          145  67500\n",
       "7   302948  Samsung          143          145  34500\n",
       "8   100132       LG           60          221  11400"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19729490\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "items_df_sf = pd.DataFrame({\n",
    "            'item_id': [417283, 849734, 132223, 573943, 19475, 3294095, 382043, 302948, 100132, 312394],\n",
    "            'vendor': ['Samsung', 'LG', 'Apple', 'Apple', 'LG', 'Apple', 'Samsung', 'Samsung', 'LG', 'ZTE'],\n",
    "            'stock_count': [54, 33, 122, 18, 102, 43, 77, 143, 60, 19]\n",
    "})\n",
    "\n",
    "purchase_df_sf = pd.DataFrame({\n",
    "            'purchase_id': [101, 101, 101, 112, 121, 145, 145, 145, 145, 221],\n",
    "            'item_id': [417283, 849734, 132223, 573943, 19475, 3294095, 382043, 302948, 103845, 100132],\n",
    "            'price': [13900, 5330, 38200, 49990, 9890, 33000, 67500, 34500, 89900, 11400]\n",
    "})\n",
    "\n",
    "merged = pd.merge(purchase_df_sf, items_df_sf, on='item_id')\n",
    "merged = merged[['item_id', 'vendor', 'stock_count', 'purchase_id', 'price']]\n",
    "display(merged)\n",
    "total_price = merged['price'] * merged['stock_count']\n",
    "income = total_price.sum()\n",
    "print(income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения задач нам понадобится выделить из признака title год выпуска фильма. Для этого напишем функцию get_year_release(arg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-07-30 18:45:03</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-07-30 18:20:47</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-07-30 18:37:04</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000-07-30 19:03:35</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000-07-30 18:48:51</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>100831</td>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-03 21:53:22</td>\n",
       "      <td>Split (2017)</td>\n",
       "      <td>Drama|Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>100832</td>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 22:21:31</td>\n",
       "      <td>John Wick: Chapter Two (2017)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>100833</td>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-08 19:50:47</td>\n",
       "      <td>Get Out (2017)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>100834</td>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 21:19:12</td>\n",
       "      <td>Logan (2017)</td>\n",
       "      <td>Action|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>100835</td>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-05-03 21:20:15</td>\n",
       "      <td>The Fate of the Furious (2017)</td>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  userId  movieId  rating                 date  \\\n",
       "0                0       1        1     4.0  2000-07-30 18:45:03   \n",
       "1                1       1        3     4.0  2000-07-30 18:20:47   \n",
       "2                2       1        6     4.0  2000-07-30 18:37:04   \n",
       "3                3       1       47     5.0  2000-07-30 19:03:35   \n",
       "4                4       1       50     5.0  2000-07-30 18:48:51   \n",
       "...            ...     ...      ...     ...                  ...   \n",
       "100831      100831     610   166534     4.0  2017-05-03 21:53:22   \n",
       "100832      100832     610   168248     5.0  2017-05-03 22:21:31   \n",
       "100833      100833     610   168250     5.0  2017-05-08 19:50:47   \n",
       "100834      100834     610   168252     5.0  2017-05-03 21:19:12   \n",
       "100835      100835     610   170875     3.0  2017-05-03 21:20:15   \n",
       "\n",
       "                                 title  \\\n",
       "0                     Toy Story (1995)   \n",
       "1              Grumpier Old Men (1995)   \n",
       "2                          Heat (1995)   \n",
       "3          Seven (a.k.a. Se7en) (1995)   \n",
       "4           Usual Suspects, The (1995)   \n",
       "...                                ...   \n",
       "100831                    Split (2017)   \n",
       "100832   John Wick: Chapter Two (2017)   \n",
       "100833                  Get Out (2017)   \n",
       "100834                    Logan (2017)   \n",
       "100835  The Fate of the Furious (2017)   \n",
       "\n",
       "                                             genres  \n",
       "0       Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                                    Comedy|Romance  \n",
       "2                             Action|Crime|Thriller  \n",
       "3                                  Mystery|Thriller  \n",
       "4                            Crime|Mystery|Thriller  \n",
       "...                                             ...  \n",
       "100831                        Drama|Horror|Thriller  \n",
       "100832                        Action|Crime|Thriller  \n",
       "100833                                       Horror  \n",
       "100834                                Action|Sci-Fi  \n",
       "100835                  Action|Crime|Drama|Thriller  \n",
       "\n",
       "[100836 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ratings_movies = pd.read_csv('data/ratings_movies.csv')\n",
    "display(ratings_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#библиотека для регулярных выражений\n",
    "import re \n",
    "def get_year_release(arg):\n",
    "    #находим все слова по шаблону \"(DDDD)\"\n",
    "    candidates = re.findall(r'\\(\\d{4}\\)', arg) \n",
    "    # проверяем число вхождений\n",
    "    if len(candidates) > 0:\n",
    "        #если число вхождений больше 0,\n",
    "\t#очищаем строку от знаков \"(\" и \")\"\n",
    "        year = candidates[0].replace('(', '')\n",
    "        year = year.replace(')', '')\n",
    "        return int(year)\n",
    "    else:\n",
    "        #если год не указан, возвращаем None\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из модуля re нам понадобится только функция findall(), которая позволяет найти в строке все слова, удовлетворяющие шаблону. Мы находим в строке с названием фильма шаблон \"(DDDD)\" — четыре цифры, обёрнутых в скобки, что соответствует году выпуска фильма. Если такого шаблона не было найдено (год выпуска не указан), функция возвращает None (в таблице это будет помечено как пропуск)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте в таблице новый признак year_release, который соответствует году выпуска фильма.\n",
    "У скольких фильмов не указан год их выпуска?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "ratings_movies[\"year_release\"] = ratings_movies[\"title\"].apply(get_year_release)\n",
    "miss_year = ratings_movies[\"year_release\"].isna().sum()\n",
    "#display(ratings_movies)\n",
    "print(miss_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой фильм, выпущенный в 1999 году, получил наименьшую среднюю оценку зрителей?\n",
    "В качестве ответа запишите название этого фильма без указания года его выпуска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bloodsport: The Dark Kumite (1999)\n"
     ]
    }
   ],
   "source": [
    "movies_in_1999 = ratings_movies[ratings_movies[\"year_release\"] == 1999]\n",
    "bad_movie = movies_in_1999.groupby('title')['rating'].mean().idxmin()\n",
    "print(bad_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какое сочетание жанров фильмов (genres), выпущенных в 2010 году, получило наименьшую среднюю оценку (rating)?\n",
    "Запишите сочетание так же, как оно указано в таблице (через разделитель |, без пробелов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action|Sci-Fi\n"
     ]
    }
   ],
   "source": [
    "bad_genres_2010 = ratings_movies[ratings_movies[\"year_release\"] == 2010]\n",
    "bad_genres = bad_genres_2010.groupby('genres')['rating'].mean().idxmin()\n",
    "print(bad_genres)\n",
    "#display(bad_genres_2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой пользователь (userId) посмотрел наибольшее количество различных (уникальных) комбинаций жанров (genres) фильмов? В качестве ответа запишите идентификатор этого пользователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599\n"
     ]
    }
   ],
   "source": [
    "user_top = ratings_movies.groupby('userId')['genres'].nunique().idxmax()\n",
    "print(user_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите пользователя, который выставил наименьшее количество оценок, но его средняя оценка фильмам наибольшая.\n",
    "В качестве ответа укажите идентификатор этого пользователя.\n",
    "Чтобы рассчитать несколько параметров для каждого пользователя (количество оценок и среднюю оценку), можно воспользоваться методом agg() на сгруппированных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId    53.0\n",
      "count     20.0\n",
      "mean       5.0\n",
      "Name: 52, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_stats = ratings_movies.groupby('userId')['rating'].agg(['count', 'mean']).reset_index()\n",
    "\n",
    "min_ratings = user_stats['count'].min()\n",
    "users_min_rat = user_stats[user_stats['count'] == min_ratings]\n",
    "\n",
    "best_user = users_min_rat.loc[users_min_rat['mean'].idxmax()]\n",
    "print(best_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите сочетание жанров (genres) за 2018 год, которое имеет наибольший средний рейтинг (среднее по столбцу rating), и при этом число выставленных ему оценок (количество значений в столбце rating) больше 10.\n",
    "Запишите сочетание так же, как оно указано в таблице (через разделитель |, без пробелов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action|Adventure|Sci-Fi\n"
     ]
    }
   ],
   "source": [
    "# Фильтрация данных за 2018 год и группировка по жанрам\n",
    "generes_stats_2018 = (\n",
    "    ratings_movies[ratings_movies[\"year_release\"] == 2018]\n",
    "    .groupby('genres')['rating']\n",
    "    .agg(['mean', 'count'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Фильтрация жанров с количеством оценок больше 10\n",
    "filtered_genres_2018 = generes_stats_2018[generes_stats_2018['count'] > 10]\n",
    "\n",
    "# Нахождение жанра с наивысшей средней оценкой\n",
    "top_genre_2018 = filtered_genres_2018.loc[filtered_genres_2018['mean'].idxmax(), 'genres']\n",
    "\n",
    "# Вывод результата\n",
    "print(top_genre_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дано два файла:\n",
    "\n",
    "orders.csv, содержащий данные о заказах;\n",
    "\n",
    "products.csv, содержащий данные о товарах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 7, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m orders \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/orders.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m products \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/products.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pupc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pupc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pupc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Pupc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 7, saw 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "orders = pd.read_csv('data/orders.csv')\n",
    "\n",
    "products = pd.read_csv('data/products.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
